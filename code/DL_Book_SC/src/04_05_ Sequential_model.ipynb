{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型语法 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型语法 2：将input_shape拿掉，以model参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "x = tf.keras.layers.Input(shape=(28, 28))\n",
    "# 或 x = tf.Variable(tf.random.truncated_normal([28, 28]))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型语法 3：可以直接串连神经层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\")\n",
    "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# Call layers on a test input\n",
    "x = tf.ones((3, 3))\n",
    "y = layer3(layer2(layer1(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 临时加减神经层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经层数: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x205bbedff70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x205bbedff10>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x205bbec55b0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 删减一层\n",
    "model.pop()\n",
    "print(f'神经层数: {len(model.layers)}')\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经层数: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x205bbedff70>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x205bbedff10>,\n",
       " <tensorflow.python.keras.layers.core.Dropout at 0x205bbec55b0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x205bbee6250>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 增加一层\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "print(f'神经层数: {len(model.layers)}')\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得模型及神经层资讯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神经层参数类别总数: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'layer1/kernel:0' shape=(28, 2) dtype=float32, numpy=\n",
       " array([[-0.10640502,  0.3605774 ],\n",
       "        [-0.08907318, -0.17315978],\n",
       "        [ 0.1200158 , -0.28237817],\n",
       "        [ 0.24987322, -0.3639028 ],\n",
       "        [ 0.15365154,  0.24755305],\n",
       "        [-0.3127381 ,  0.10788786],\n",
       "        [ 0.08372974, -0.22560312],\n",
       "        [ 0.3914864 ,  0.09738165],\n",
       "        [-0.19479197, -0.01712051],\n",
       "        [ 0.12762403, -0.26360968],\n",
       "        [ 0.12762141,  0.2805773 ],\n",
       "        [ 0.13974649,  0.12249672],\n",
       "        [ 0.36713785,  0.40628284],\n",
       "        [ 0.42620873, -0.04030997],\n",
       "        [ 0.43528122, -0.32735592],\n",
       "        [ 0.31521922,  0.07268167],\n",
       "        [ 0.27168196,  0.1796459 ],\n",
       "        [ 0.22482169,  0.04790714],\n",
       "        [ 0.25158632,  0.2119981 ],\n",
       "        [-0.37386125, -0.3107264 ],\n",
       "        [ 0.3775435 , -0.20909612],\n",
       "        [-0.13379535,  0.44203997],\n",
       "        [ 0.05903548,  0.03686729],\n",
       "        [ 0.0125601 , -0.41514012],\n",
       "        [-0.36170176,  0.4320925 ],\n",
       "        [ 0.00438523,  0.25991344],\n",
       "        [-0.03942499,  0.18630052],\n",
       "        [-0.05937487,  0.21613872]], dtype=float32)>,\n",
       " <tf.Variable 'layer1/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
       " array([[-0.12554866, -0.88298076, -0.7784833 ],\n",
       "        [-0.2880749 ,  0.4587078 , -0.09641045]], dtype=float32)>,\n",
       " <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'layer3/kernel:0' shape=(3, 4) dtype=float32, numpy=\n",
       " array([[ 0.49654424, -0.12902665, -0.7866846 , -0.54560447],\n",
       "        [-0.76750356, -0.82305443,  0.8115115 , -0.77345604],\n",
       "        [-0.5143507 , -0.73272955,  0.8451171 , -0.82455564]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'layer3/bias:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立 3 layers\n",
    "layer1 = tf.keras.layers.Dense(2, activation=\"relu\", name=\"layer1\", \n",
    "                               input_shape=(28, 28))\n",
    "layer2 = tf.keras.layers.Dense(3, activation=\"relu\", name=\"layer2\")\n",
    "layer3 = tf.keras.layers.Dense(4, name=\"layer3\")\n",
    "\n",
    "# 建立模型\n",
    "model = tf.keras.models.Sequential([\n",
    "  layer1,\n",
    "  layer2,\n",
    "  layer3\n",
    "])\n",
    "\n",
    "# 读取模型权重\n",
    "print(f'神经层参数类别总数: {len(model.weights)}')\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer2: [<tf.Variable 'layer2/kernel:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[-0.12554866, -0.88298076, -0.7784833 ],\n",
      "       [-0.2880749 ,  0.4587078 , -0.09641045]], dtype=float32)>, <tf.Variable 'layer2/bias:0' shape=(3,) dtype=float32, numpy=array([0., 0., 0.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "print(f'{layer2.name}: {layer2.weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 28, 2)             58        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 28, 3)             9         \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 28, 4)             16        \n",
      "=================================================================\n",
      "Total params: 83\n",
      "Trainable params: 83\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 取得模型汇总资讯\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一边加神经层，一边显示模型汇总资讯，以利除错"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "=================================================================\n",
      "Total params: 11,680\n",
      "Trainable params: 11,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 123, 32)      2432      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 121, 121, 32)      9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 38, 38, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 36, 36, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "=================================================================\n",
      "Total params: 48,672\n",
      "Trainable params: 48,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.Input(shape=(250, 250, 3)))  # 250x250 RGB images\n",
    "model.add(layers.Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "\n",
    "# 显示目前模型汇总资讯\n",
    "model.summary()\n",
    "\n",
    "# The answer was: (40, 40, 32), so we can keep downsampling...\n",
    "\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(3))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(layers.MaxPooling2D(2))\n",
    "\n",
    "# 显示目前模型汇总资讯\n",
    "model.summary()\n",
    "\n",
    "# Now that we have 4x4 feature maps, time to apply global max pooling.\n",
    "model.add(layers.GlobalMaxPooling2D())\n",
    "\n",
    "# Finally, we add a classification layer.\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 取得每一层神经层的output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 123, 123, 32), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362364, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.02362365, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362365, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.02362365, 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.3641286 ,\n",
       "           0.        , 0.5561205 ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.36412853,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.36412853,\n",
       "           0.        , 0.5561205 ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.36412853,\n",
       "           0.        , 0.55612034]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 119, 119, 32), dtype=float32, numpy=\n",
       " array([[[[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034318, 0.        , ..., 0.31926972,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.12034313, 0.        , ..., 0.31926978,\n",
       "           0.        , 0.        ]]]], dtype=float32)>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设定模型\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 设定模型的 input/output\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=[layer.output for layer in initial_model.layers],\n",
    ")\n",
    "\n",
    "# 呼叫 feature_extractor 取得 output\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 121, 121, 32), dtype=float32, numpy=\n",
       "array([[[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073]],\n",
       "\n",
       "        [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350073],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.3835007 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.3835007 ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.38350064]]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设定模型\n",
    "initial_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(250, 250, 3)),\n",
    "        layers.Conv2D(32, 5, strides=2, activation=\"relu\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", name=\"my_intermediate_layer\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 设定模型的 input/output\n",
    "feature_extractor = tf.keras.Model(\n",
    "    inputs=initial_model.inputs,\n",
    "    outputs=initial_model.get_layer(name=\"my_intermediate_layer\").output,\n",
    ")\n",
    "\n",
    "# 呼叫 feature_extractor 取得 output\n",
    "x = tf.ones((1, 250, 250, 3))\n",
    "features = feature_extractor(x)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
