{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 影评资料集(IMDB movie review)情绪分析 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入相关套件\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数设定\n",
    "batch_size = 128            # 批量\n",
    "embedding_output_dims = 15  # 嵌入层输出维度\n",
    "max_sequence_length = 300   # 句子最大字数\n",
    "num_distinct_words = 5000   # 字典\n",
    "number_of_epochs = 5        # 训练执行周期\n",
    "validation_split = 0.20     # 验证资料比例\n",
    "verbosity_mode = 1          # 训练资料讯息显示程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入 IMDB 影评资料集，TensorFlow 已将资料转为索引值\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(\n",
    "    num_words=num_distinct_words)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# 长度不足时补 0\n",
    "padded_inputs = pad_sequences(x_train, maxlen=max_sequence_length\n",
    "                              , value = 0.0) \n",
    "padded_inputs_test = pad_sequences(x_test, maxlen=max_sequence_length\n",
    "                                   , value = 0.0) \n",
    "\n",
    "# 建立模型\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_distinct_words, embedding_output_dims, \n",
    "                    input_length=max_sequence_length))\n",
    "model.add(LSTM(10))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 指定优化器、损失函数\n",
    "model.compile(optimizer=Adam(), loss=BinaryCrossentropy, metrics=['accuracy'])\n",
    "\n",
    "# 模型汇总资讯\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 15)           75000     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 10)                1040      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 76,051\n",
      "Trainable params: 76,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "20000/20000 [==============================] - ETA: 0s - loss: 0.6119 - accuracy: 0.6847"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 143s 7ms/sample - loss: 0.6119 - accuracy: 0.6847 - val_loss: 0.4529 - val_accuracy: 0.8368\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 146s 7ms/sample - loss: 0.3766 - accuracy: 0.8580 - val_loss: 0.3708 - val_accuracy: 0.8474\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 148s 7ms/sample - loss: 0.2897 - accuracy: 0.8947 - val_loss: 0.3277 - val_accuracy: 0.8694\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 148s 7ms/sample - loss: 0.2481 - accuracy: 0.9115 - val_loss: 0.3570 - val_accuracy: 0.8620\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 144s 7ms/sample - loss: 0.2160 - accuracy: 0.9264 - val_loss: 0.3258 - val_accuracy: 0.8714\n",
      "Test results - Loss: 0.33703479669570924 - Accuracy: 86.62800192832947%\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(padded_inputs, y_train, batch_size=batch_size, \n",
    "            epochs=number_of_epochs, verbose=verbosity_mode, \n",
    "            validation_split=validation_split)\n",
    "\n",
    "# 模型评估\n",
    "test_results = model.evaluate(padded_inputs_test, y_test, verbose=False)\n",
    "print(f'Loss: {test_results[0]}, Accuracy: {100*test_results[1]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型存档\n",
    "model.save('LSTM_IMDB.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fawn',\n",
       " 'tsukino',\n",
       " 'nunnery',\n",
       " 'sonja',\n",
       " 'vani',\n",
       " 'woods',\n",
       " 'spiders',\n",
       " 'hanging',\n",
       " 'woody',\n",
       " 'trawling']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 取得字词与索引的对照表字典\n",
    "imdb_dict = imdb.get_word_index()\n",
    "list(imdb_dict.keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 反转字典，变成索引与字词的对照表\n",
    "imdb_dict_reversed = {}\n",
    "for k, v in imdb_dict.items():\n",
    "    imdb_dict_reversed[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,the,wonder,own,as,by,is,sequence,i,i,and,and,to,of,hollywood,br,of,down,and,getting,boring,of,ever,it,sadly,sadly,sadly,i,i,was,then,does,don't,close,and,after,one,carry,as,by,are,be,and,all,family,turn,in,does,as,three,part,in,another,some,to,be,probably,with,world,and,her,an,have,and,beginning,own,as,is,sequence,\",\n",
       " \" , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , , ,the,as,you,world's,is,quite,br,and,most,that,quest,are,chase,to,being,quickly,of,little,it,time,hell,to,plot,br,of,something,long,put,are,of,every,place,this,and,and,of,and,storytelling,being,nasty,not,of,you,warren,in,is,failed,club,i,i,of,films,pay,so,sequences,and,film,okay,uses,to,received,and,if,time,done,for,room,and,viewer,as,cartoon,of,gives,to,forgettable,br,be,because,many,these,of,and,and,contained,gives,it,wreck,scene,to,more,was,two,when,had,find,as,you,another,it,of,themselves,probably,who,and,storytelling,if,itself,by,br,about,1950's,films,not,would,effects,that,her,box,to,miike,for,if,hero,close,seek,end,is,very,together,movie,of,and,got,say,kong,and,fred,close,bore,there,is,playing,lot,of,and,pan,place,trilogy,of,lacks,br,of,their,time,much,this,men,as,on,it,is,telling,program,br,and,okay,and,to,frustration,at,corner,and,she,of,sequences,to,political,clearly,in,of,drugs,keep,guy,i,i,was,throwing,room,and,as,it,by,br,be,plot,many,for,occasionally,film,and,boyfriend,difficult,kid,as,you,it,failed,not,if,gerard,to,if,woman,in,and,is,police,fi,spooky,or,of,self,what,have,pretty,in,can,so,suit,you,good,2,which,why,super,as,it,main,of,my,i,i,\\x96,if,time,screenplay,in,same,this,remember,and,have,action,one,in,realistic,that,better,of,lessons,\"]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 还原测试资料前两笔为文字\n",
    "text = []\n",
    "for i, line in enumerate(padded_inputs_test[:2]):\n",
    "    text.append('')\n",
    "    for j, word in enumerate(line):\n",
    "        if word != 0:\n",
    "            text[i] += imdb_dict_reversed[word]+','\n",
    "        else:\n",
    "            text[i] += ' ,'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'as'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_dict_reversed[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以上述语句测试\n",
    "X_tokens = []\n",
    "for line in text:\n",
    "    tokens = nltk.word_tokenize(line)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    X_tokens.append(tokens)\n",
    "    \n",
    "# 转为索引值\n",
    "import numpy as np\n",
    "X_index = np.zeros((len(text), max_sequence_length))\n",
    "for i, line in enumerate(X_tokens):\n",
    "    for j, word in enumerate(line):\n",
    "        if j >= max_sequence_length:\n",
    "            break\n",
    "        if word in imdb_dict:\n",
    "            X_index[i, j] = imdb_dict[word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 长度不足时补 0\n",
    "padded_inputs = pad_sequences(X_index, maxlen=max_sequence_length, \n",
    "                      padding=pad_type, truncating=trunc_type, value = 0.0) \n",
    "\n",
    "# 预测\n",
    "np.argmax(model.predict(padded_inputs), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以原资料预测，确认答案相同\n",
    "np.argmax(model.predict(padded_inputs_test[:2]), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
