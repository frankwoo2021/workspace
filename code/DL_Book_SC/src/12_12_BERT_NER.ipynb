{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 命名实体标注(Named Entity Recognition, NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入相关套件\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入模型\n",
    "nlp = pipeline(\"ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>entity</th>\n",
       "      <th>index</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hu</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>##gging</td>\n",
       "      <td>0.989597</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Face</td>\n",
       "      <td>0.997970</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Inc</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>York</td>\n",
       "      <td>0.999193</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>12</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>City</td>\n",
       "      <td>0.999341</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>13</td>\n",
       "      <td>49</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>D</td>\n",
       "      <td>0.986336</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>19</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>##UM</td>\n",
       "      <td>0.939624</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>20</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>##BO</td>\n",
       "      <td>0.912139</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>0.983919</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>29</td>\n",
       "      <td>113</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Bridge</td>\n",
       "      <td>0.992424</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>30</td>\n",
       "      <td>123</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word     score entity  index  start  end\n",
       "0          Hu  0.999511  I-ORG      1      0    2\n",
       "1     ##gging  0.989597  I-ORG      2      2    7\n",
       "2        Face  0.997970  I-ORG      3      8   12\n",
       "3         Inc  0.999376  I-ORG      4     13   16\n",
       "4         New  0.999341  I-LOC     11     40   43\n",
       "5        York  0.999193  I-LOC     12     44   48\n",
       "6        City  0.999341  I-LOC     13     49   53\n",
       "7           D  0.986336  I-LOC     19     79   80\n",
       "8        ##UM  0.939624  I-LOC     20     80   82\n",
       "9        ##BO  0.912139  I-LOC     21     82   84\n",
       "10  Manhattan  0.983919  I-LOC     29    113  122\n",
       "11     Bridge  0.992424  I-LOC     30    123  129"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 测试资料\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. \" \\\n",
    "           \"Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# 推测答案\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(nlp(sequence))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结合Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8da5ed29734cbc9e76e53dbb3b165f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing TFBertForTokenClassification: ['dropout_147']\n",
      "- This IS expected if you are initializing TFBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForTokenClassification were initialized from the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7a0157ed304305b1bce46cf4a4d340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9e01e6e47442d8ad3724b05757e64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e3c7ccb83e428e888d9fcd9e3a2332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0371fb496847c0aa7e07751780a8f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 载入相关套件\n",
    "from transformers import TFAutoModelForTokenClassification, AutoTokenizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# 结合分词器(Tokenizer)\n",
    "model_name = \"dbmdz/bert-large-cased-finetuned-conll03-english\"\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[CLS]', 'O'), ('Hu', 'I-ORG'), ('##gging', 'I-ORG'), ('Face', 'I-ORG'), ('Inc', 'I-ORG'), ('.', 'O'), ('is', 'O'), ('a', 'O'), ('company', 'O'), ('based', 'O'), ('in', 'O'), ('New', 'I-LOC'), ('York', 'I-LOC'), ('City', 'I-LOC'), ('.', 'O'), ('Its', 'O'), ('headquarters', 'O'), ('are', 'O'), ('in', 'O'), ('D', 'I-LOC'), ('##UM', 'I-LOC'), ('##BO', 'I-LOC'), (',', 'O'), ('therefore', 'O'), ('very', 'O'), ('##c', 'O'), ('##lose', 'O'), ('to', 'O'), ('the', 'O'), ('Manhattan', 'I-LOC'), ('Bridge', 'I-LOC'), ('.', 'O'), ('[SEP]', 'O')]\n"
     ]
    }
   ],
   "source": [
    "# NER 类别 \n",
    "label_list = [\n",
    "    \"O\",       # 非实体\n",
    "    \"B-MISC\",  # 杂项实体的开头，接在另一杂项实体的后面\n",
    "    \"I-MISC\",  # 杂项实体\n",
    "    \"B-PER\",   # 人名的开头，接在另一人名的后面\n",
    "    \"I-PER\",   # 人名\n",
    "    \"B-ORG\",   # 组织的开头，接在另一组织的后面\n",
    "    \"I-ORG\",   # 组织\n",
    "    \"B-LOC\",   # 地名的开头，接在另一地名的后面\n",
    "    \"I-LOC\"    # 地名\n",
    "]\n",
    "\n",
    "# 测试资料\n",
    "sequence = \"Hugging Face Inc. is a company based in New York City. \" \\\n",
    "           \"Its headquarters are in DUMBO, therefore very\" \\\n",
    "           \"close to the Manhattan Bridge.\"\n",
    "\n",
    "# 推测答案\n",
    "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
    "inputs = tokenizer.encode(sequence, return_tensors=\"tf\")\n",
    "outputs = model(inputs)[0]\n",
    "predictions = tf.argmax(outputs, axis=2)\n",
    "print([(token, label_list[prediction]) for token, prediction in \n",
    "       zip(tokens, predictions[0].numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
