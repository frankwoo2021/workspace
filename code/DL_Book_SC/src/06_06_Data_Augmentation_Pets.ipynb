{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 资料增补 (Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PWuaygl9NQD-"
   },
   "outputs": [],
   "source": [
    "# 载入套件\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xg5BjAmKNQD9"
   },
   "source": [
    "## 从网路取得压缩档，并解压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip\n",
      "191922176/824894548 [=====>........................] - ETA: 5:20"
     ]
    }
   ],
   "source": [
    "# 从网路取得压缩档，并解压缩\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "# 压缩档 URL\n",
    "zip_file_path = 'https://download.microsoft.com/download/3/E/1/'\n",
    "zip_file_path += '3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip'\n",
    "\n",
    "# 存档路径\n",
    "zip_file = os.path.join(os.getcwd(), 'CatAndDog.zip')\n",
    "\n",
    "# 若压缩档案不存在，则下载档案\n",
    "if not os.path.exists(zip_file):\n",
    "    tf.keras.utils.get_file(\n",
    "        os.path.join(zip_file),\n",
    "        zip_file_path,\n",
    "        archive_format='auto'\n",
    "    )\n",
    "\n",
    "# 若解压缩目录不存在，则解压缩档案至 unzip_path\n",
    "unzip_path = os.path.join(os.getcwd(), 'CatAndDog')\n",
    "if not os.path.exists(unzip_path):\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(unzip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e4y5yj2qNQEK"
   },
   "source": [
    "## 过滤不合格的档案\n",
    "\n",
    "#### 扫描每一个档案，若表头不含\"JFIF\"，即为不合格的档案，不纳入训练资料内。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmwzUWYeNQEK"
   },
   "outputs": [],
   "source": [
    "# 扫描每一个档案，若表头不含\"JFIF\"，即为不合格的档案，不纳入训练资料内。\n",
    "num_skipped = 0   # 记录删除的档案个数\n",
    "# 扫描目录\n",
    "for folder_name in (\"Cat\", \"Dog\"):\n",
    "    folder_path = os.path.join(unzip_path, \"PetImages\", folder_name)\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10)\n",
    "        finally:\n",
    "            fobj.close()\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1\n",
    "            # 删除档案\n",
    "            os.remove(fpath)\n",
    "\n",
    "print(f\"删除 {num_skipped} 个档案\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CNThHNSINQEN"
   },
   "source": [
    "## 以档案目录为基础，建立训练(Training)及验证(Validation)资料集(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ufL6yMc-NQEO"
   },
   "outputs": [],
   "source": [
    "# image_dataset_from_directory：读取目录中的档案，存入 dataset\n",
    "# image_dataset_from_directory：tf v2.3.0 才支援\n",
    "\n",
    "image_size = (180, 180)  # 影像尺寸\n",
    "batch_size = 32          # 批量\n",
    "\n",
    "# 训练资料集(Dataset)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(unzip_path, \"PetImages\"),\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "# 验证(Validation)资料集\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    os.path.join(unzip_path, \"PetImages\"),\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TFzDiMqBNQEQ"
   },
   "source": [
    "## 显示训练资料前9笔影像\n",
    "### 标注为1是狗(dog)，0是猫(cat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY8rZu0XNQER"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 显示训练资料前9笔影像\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3OR2r-mpNQET"
   },
   "source": [
    "## 定义资料增补(Data Augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oYE2VzuNQEU"
   },
   "outputs": [],
   "source": [
    "# RandomFlip(\"horizontal\")：水平翻转\n",
    "# RandomRotation(0.1)：旋转 0.1 比例 \n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "srOOhshxNQEX"
   },
   "source": [
    "## 显示资料增补后的影像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FrCxObm4NQEX"
   },
   "outputs": [],
   "source": [
    "# 显示资料增补后的影像\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yQzkguzyNQEa"
   },
   "source": [
    "## prefetch：预先读取训练资料，以提升效能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFrHB7hlNQEa"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lm6GMvBsNQEc"
   },
   "source": [
    "## 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0aU0akvsNQEd"
   },
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # 特征缩放\n",
    "    x = layers.experimental.preprocessing.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "# 建立模型\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "\n",
    "# 绘制模型结构\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iJFF8NStNQEf"
   },
   "source": [
    "## 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b7rWDOBRNQEf"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "# 设定优化器(optimizer)、损失函数(loss)、效能衡量指标(metrics)的类别\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-3),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# 模型训练\n",
    "model.fit(\n",
    "    train_ds, epochs=epochs, validation_data=val_ds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbhiW9FfNQEj"
   },
   "source": [
    "### 训练 50 epochs，验证准确率可达 96%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "etzhur02NQEj"
   },
   "source": [
    "## 从目录中任选一个档案测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型存档\n",
    "model.save('./pet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型载入\n",
    "model = tf.keras.models.load_model('./pet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FC2thF3NQEk"
   },
   "outputs": [],
   "source": [
    "# 任取一笔资料测试\n",
    "img = keras.preprocessing.image.load_img(\n",
    "    os.path.join(unzip_path, \"PetImages/Cat/18.jpg\"), target_size=image_size\n",
    ")\n",
    "img_array = keras.preprocessing.image.img_to_array(img) # 将影像转为阵列\n",
    "img_array = tf.expand_dims(img_array, 0)  # 增加一维在最前面，代表一笔资料\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "score = predictions[0][0]\n",
    "print(f\"是猫的机率= {(100 * score):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_classification_from_scratch",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
